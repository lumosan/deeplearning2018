{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Nearest Neighbor\n",
    "\n",
    "Write a function that gets a training set and a test sample and returns the label of the training point\n",
    "the closest to the latter.\n",
    "\n",
    "More precisely, write:\n",
    "\n",
    "`def nearest_classification(train_input, train_target, x):`\n",
    "\n",
    "where\n",
    "* `train_input` is a 2d float tensor of dimension n × d containing the training vectors,\n",
    "* `train_target` is a 1d long tensor of dimension n containing the training labels,\n",
    "* `x` is 1d float tensor of dimension d containing the test vector,\n",
    "\n",
    "and the returned value is the class of the train sample closest to $x$ for the $L^2$ norm\n",
    "\n",
    "**Hint:** The function should have no python loop, and may use in particular `torch.mean` , `torch.view` ,\n",
    "`torch.pow` , `torch.sum` , and `torch.sort` or `torch.min`\n",
    "\n",
    "My version is 164 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_classification(train_input, train_target, x):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Error estimation\n",
    "\n",
    "Write a function\n",
    "\n",
    "`def compute_nb_errors(train_input, train_target, test_input, test_target, mean = None, proj = None):`\n",
    "\n",
    "where\n",
    "* `train_input` is a 2d float tensor of dimension n × d containing the train vectors,\n",
    "* `train_target` is a 1d long tensor of dimension n containing the train labels,\n",
    "* `test_input` is a 2d float tensor of dimension m × d containing the test vectors,\n",
    "* `test_target` is a 1d long tensor of dimension m containing the test labels,\n",
    "* `mean` is either None or a 1d float tensor of dimension d,\n",
    "* `proj` is either None or a 2d float tensor of dimension c × d,\n",
    "that subtracts `mean` (if it is not None) from the vectors of both `train_input` and `test_input`, apply\n",
    "the operator proj (if it is not None) to both, and returns the number of classification errors using the\n",
    "1-nearest-neighbor rule on the resulting data.\n",
    "\n",
    "**Hint:** Use in particular `torch.mm` . My version is 487 characters long, and it has a loop (the horror!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_nb_errors(train_input, train_target, test_input, test_target, mean = None, proj = None):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 PCA\n",
    "Write a function\n",
    "\n",
    "`def PCA(x):`\n",
    "\n",
    "where x is a 2d float tensor of dimension n × d, which returns a pair composed of the 1d mean vector\n",
    "of dimension d and the PCA basis, ranked in decreasing order of the eigen-values, as a 2d tensor of\n",
    "dimension d × d.\n",
    "\n",
    "**Hint:** The function should have no python loop, and use in particular torch.eig , and torch.sort .\n",
    "My version is 275 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(x):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Check that all this makes sense\n",
    "\n",
    "Compare the performance of the 1-nearest neighbor rule on data projected either a 100d random subspace\n",
    "(i.e. using a basis generated with a normal) and using the PCA basis for different dimensions (e.g. 3,\n",
    "10, 50, 100).\n",
    "\n",
    "Compare also the performance between MNIST and CIFAR. Does all this make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
