{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Nearest Neighbor\n",
    "\n",
    "Write a function that gets a training set and a test sample and returns the label of the training point\n",
    "the closest to the latter.\n",
    "\n",
    "More precisely, write:\n",
    "\n",
    "`def nearest_classification(train_input, train_target, x):`\n",
    "\n",
    "where\n",
    "* `train_input` is a 2d float tensor of dimension n × d containing the training vectors,\n",
    "* `train_target` is a 1d long tensor of dimension n containing the training labels,\n",
    "* `x` is 1d float tensor of dimension d containing the test vector,\n",
    "\n",
    "and the returned value is the class of the train sample closest to $x$ for the $L^2$ norm\n",
    "\n",
    "**Hint:** The function should have no python loop, and may use in particular `torch.mean` , `torch.view` ,\n",
    "`torch.pow` , `torch.sum` , and `torch.sort` or `torch.min`\n",
    "\n",
    "My version is 164 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_classification(train_input, train_target, x):\n",
    "    dist = (train_input - x).pow(2).sum(dim=1)#.view(-1)\n",
    "    n = dist.sort()[1]\n",
    "    return train_target[n[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Error estimation\n",
    "\n",
    "Write a function\n",
    "\n",
    "`def compute_nb_errors(train_input, train_target, test_input, test_target, mean = None, proj = None):`\n",
    "\n",
    "where\n",
    "* `train_input` is a 2d float tensor of dimension n × d containing the train vectors,\n",
    "* `train_target` is a 1d long tensor of dimension n containing the train labels,\n",
    "* `test_input` is a 2d float tensor of dimension m × d containing the test vectors,\n",
    "* `test_target` is a 1d long tensor of dimension m containing the test labels,\n",
    "* `mean` is either None or a 1d float tensor of dimension d,\n",
    "* `proj` is either None or a 2d float tensor of dimension c × d\n",
    "\n",
    "that subtracts `mean` (if it is not None) from the vectors of both `train_input` and `test_input`, apply\n",
    "the operator proj (if it is not None) to both, and returns the number of classification errors using the\n",
    "1-nearest-neighbor rule on the resulting data.\n",
    "\n",
    "**Hint:** Use in particular `torch.mm` . My version is 487 characters long, and it has a loop (the horror!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_nb_errors(train_input, train_target, test_input,\n",
    "    test_target, mean = None, proj = None):\n",
    "    train = train_input.copy()\n",
    "    test = test_input.copy()\n",
    "    \n",
    "    if mean is not None:\n",
    "        train -= mean\n",
    "        test -= mean\n",
    "    if proj is not None:\n",
    "        train = train.mm(proj.t())\n",
    "        test = test.mm(proj.t())\n",
    "        \n",
    "    n_err = 0\n",
    "    for i in range(test_input.size()[0]):\n",
    "        # For each sample, check if it's correctly labelled\n",
    "        comp = nearest_classification(train_input, train_target, test_input[n])\n",
    "        if comp == test_target[n]:\n",
    "            n_err += 1\n",
    "        return n_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 PCA\n",
    "Write a function\n",
    "\n",
    "`def PCA(x):`\n",
    "\n",
    "where x is a 2d float tensor of dimension n × d, which returns a pair composed of the 1d mean vector\n",
    "of dimension d and the PCA basis, ranked in decreasing order of the eigen-values, as a 2d tensor of\n",
    "dimension d × d.\n",
    "\n",
    "**Hint:** The function should have no python loop, and use in particular torch.eig , and torch.sort .\n",
    "My version is 275 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(x):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Check that all this makes sense\n",
    "\n",
    "Compare the performance of the 1-nearest neighbor rule on data projected either a 100d random subspace\n",
    "(i.e. using a basis generated with a normal) and using the PCA basis for different dimensions (e.g. 3,\n",
    "10, 50, 100).\n",
    "\n",
    "Compare also the performance between MNIST and CIFAR. Does all this make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
